#!/usr/bin/env python3
"""
–û—Ç–ª–∞–¥–æ—á–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–≥—Ä—ã Pull Up-–§–∞—Ä–º
"""

import asyncio
import aiohttp
from bs4 import BeautifulSoup
import re

async def debug_pullup_farm():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–≥—Ä—É Pull Up-–§–∞—Ä–º"""
    url = "http://letobasket.ru/"
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status == 200:
                    html_content = await response.text()
                    
                    # –ü–∞—Ä—Å–∏–º HTML
                    soup = BeautifulSoup(html_content, 'html.parser')
                    
                    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    page_text = soup.get_text()
                    
                    print("üîç –ê–ù–ê–õ–ò–ó –ò–ì–†–´ PULL UP-–§–ê–†–ú")
                    print("=" * 50)
                    
                    # –ò—â–µ–º Pull Up-–§–∞—Ä–º
                    pullup_farm_pattern = r'Pull Up-–§–∞—Ä–º'
                    matches = re.findall(pullup_farm_pattern, page_text, re.IGNORECASE)
                    
                    print(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(matches)}")
                    
                    for i, match in enumerate(matches, 1):
                        print(f"\nüéÆ –ê–ù–ê–õ–ò–ó PULL UP-–§–ê–†–ú {i}:")
                        print("-" * 35)
                        
                        # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                        match_pos = page_text.lower().find(match.lower())
                        if match_pos != -1:
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                            start_context = max(0, match_pos - 400)
                            end_context = min(len(page_text), match_pos + 500)
                            context = page_text[start_context:end_context]
                            
                            print(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:")
                            print(context)
                            
                            # –ò—â–µ–º –¥–∞—Ç—É –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                            print(f"\nüìÖ –ü–û–ò–°–ö –î–ê–¢–´:")
                            date_match = re.search(r'(\d{1,2}[./]\d{1,2}[./]\d{2,4})', context)
                            if date_match:
                                print(f"   ‚úÖ –î–∞—Ç–∞: {date_match.group(1)}")
                            else:
                                print(f"   ‚ùå –î–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                            
                            # –ò—â–µ–º –∫–æ–º–∞–Ω–¥—É —Å–æ–ø–µ—Ä–Ω–∏–∫–∞
                            print(f"\nüîç –ü–û–ò–°–ö –°–û–ü–ï–†–ù–ò–ö–ê:")
                            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω: –ö–æ–º–∞–Ω–¥–∞1 - –ö–æ–º–∞–Ω–¥–∞2
                            opponent_match = re.search(r'([–ê-–Ø][–∞-—è\s]+)\s*-\s*([–ê-–Ø][–∞-—è\s]+)', context)
                            if opponent_match:
                                team1 = opponent_match.group(1).strip()
                                team2 = opponent_match.group(2).strip()
                                print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ: {team1} - {team2}")
                                
                                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ–ø–µ—Ä–Ω–∏–∫–∞
                                if 'pull' in team1.lower() and 'up' in team1.lower():
                                    print(f"   üèÄ –°–æ–ø–µ—Ä–Ω–∏–∫: {team2}")
                                elif 'pull' in team2.lower() and 'up' in team2.lower():
                                    print(f"   üèÄ –°–æ–ø–µ—Ä–Ω–∏–∫: {team1}")
                                else:
                                    print(f"   ‚ùì –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–æ–ø–µ—Ä–Ω–∏–∫–∞")
                            else:
                                print(f"   ‚ùå –°–æ–ø–µ—Ä–Ω–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                            
                            # –ò—â–µ–º –≤—Ä–µ–º—è
                            print(f"\nüïê –ü–û–ò–°–ö –í–†–ï–ú–ï–ù–ò:")
                            time_match = re.search(r'(\d{1,2}[:.]\d{2})', context)
                            if time_match:
                                print(f"   ‚úÖ –í—Ä–µ–º—è: {time_match.group(1)}")
                            else:
                                print(f"   ‚ùå –í—Ä–µ–º—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                            
                            # –ò—â–µ–º —Å—á–µ—Ç
                            print(f"\nüèÄ –ü–û–ò–°–ö –°–ß–ï–¢–ê:")
                            score_match = re.search(r'(\d+)\s*[-‚Äî]\s*(\d+)', context)
                            if score_match:
                                print(f"   ‚úÖ –°—á–µ—Ç: {score_match.group(1)}:{score_match.group(2)}")
                            else:
                                print(f"   ‚ùå –°—á–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
                            
                            # –ò—â–µ–º —Å—Å—ã–ª–∫—É –≤ HTML
                            print(f"\nüîó –ü–û–ò–°–ö –°–°–´–õ–ö–ò:")
                            context_start = html_content.lower().find(context[:50].lower())
                            if context_start != -1:
                                search_start = max(0, context_start - 1000)
                                search_end = min(len(html_content), context_start + 1000)
                                search_area = html_content[search_start:search_end]
                                
                                # –ò—â–µ–º "–°–¢–†–ê–ù–ò–¶–ê –ò–ì–†–´"
                                page_link_match = re.search(r'–°–¢–†–ê–ù–ò–¶–ê –ò–ì–†–´[^>]*href=["\']([^"\']+)["\']', search_area, re.IGNORECASE)
                                if page_link_match:
                                    print(f"   ‚úÖ –°—Å—ã–ª–∫–∞ –Ω–∞–π–¥–µ–Ω–∞: {page_link_match.group(1)}")
                                else:
                                    print(f"   ‚ùå –°—Å—ã–ª–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                                    
                                    # –ò—â–µ–º –ª—é–±—ã–µ —Å—Å—ã–ª–∫–∏
                                    all_links = re.findall(r'href=["\']([^"\']+)["\']', search_area)
                                    if all_links:
                                        print(f"   üìã –ù–∞–π–¥–µ–Ω–æ {len(all_links)} —Å—Å—ã–ª–æ–∫ –≤ –æ–±–ª–∞—Å—Ç–∏:")
                                        for link in all_links[:10]:
                                            print(f"      - {link}")
                            else:
                                print(f"   ‚ùå –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ HTML")
                    
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {response.status}")
                    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    asyncio.run(debug_pullup_farm())
