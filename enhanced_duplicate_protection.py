#!/usr/bin/env python3
"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∑–∞—â–∏—Ç—ã –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–∏—Å—Ç "–°–µ—Ä–≤–∏—Å–Ω—ã–π" –≤ Google —Ç–∞–±–ª–∏—Ü–µ –¥–ª—è —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è
"""

import os
import json
import re
from typing import Any, Dict, List, Optional, Set, Tuple
from dotenv import load_dotenv
import gspread
from google.oauth2.service_account import Credentials
from datetime_utils import get_moscow_time

SERVICE_HEADER = [
    "–¢–ò–ü –î–ê–ù–ù–´–•",
    "–î–ê–¢–ê –ò –í–†–ï–ú–Ø",
    "–£–ù–ò–ö–ê–õ–¨–ù–´–ô –ö–õ–Æ–ß",
    "–°–¢–ê–¢–£–°",
    "–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï",
    "–°–°–´–õ–ö–ê",
    "–ò–î –°–û–†–ï–í–ù–û–í–ê–ù–ò–Ø",
    "–ò–î –ö–û–ú–ê–ù–î–´",
    "–ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–û–ï –ò–ú–Ø",
    "–ù–ê–°–¢–†–û–ô–ö–ò",
    "GAME ID",
    "GAME DATE",
    "GAME TIME",
    "–ê–†–ï–ù–ê",
    "TEAM A ID",
    "TEAM B ID",
]

# –ò–Ω–¥–µ–∫—Å—ã –∫–æ–ª–æ–Ω–æ–∫ (0-based)
TYPE_COL = 0
DATE_COL = 1
KEY_COL = 2
STATUS_COL = 3
ADDITIONAL_DATA_COL = 4
LINK_COL = 5
COMP_ID_COL = 6
TEAM_ID_COL = 7
ALT_NAME_COL = 8
CONFIG_COL = 9
GAME_ID_COL = 10
GAME_DATE_COL = 11
GAME_TIME_COL = 12
ARENA_COL = 13
TEAM_A_ID_COL = 14
TEAM_B_ID_COL = 15

END_COLUMN_LETTER = chr(ord('A') + len(SERVICE_HEADER) - 1)
CONFIG_WORKSHEET_NAME = "–ö–æ–Ω—Ñ–∏–≥"
CONFIG_HEADER = [
    "–¢–ò–ü",
    "–ò–î (–°–û–†–ï–í–ù–û–í–ê–ù–ò–Ø / –ì–û–õ–û–°–û–í–ê–ù–ò–Ø)",
    "–ò–î –ö–û–ú–ê–ù–î–´ / –ü–û–†–Ø–î–û–ö",
    "–ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–û–ï –ò–ú–Ø / –¢–ï–ö–°–¢",
    "–ù–ê–°–¢–†–û–ô–ö–ò (JSON)",
    "–î–ù–ò –ù–ï–î–ï–õ–ò",
    "URL FALLBACK",
    "–ù–ê–ó–í–ê–ù–ò–ï FALLBACK"
]
CONFIG_SECTION_END_MARKERS = {
    "END",
    "END_CONFIG",
    "CONFIG_END",
    "END OF CONFIG",
    "–ö–û–ù–ï–¶",
    "--- END ---",
    "=== END ===",
}
DEFAULT_END_MARKER = "--- END ---"
VOTING_SECTION_END_MARKER = "--- END VOTING ---"
VOTING_SECTION_HEADER = [
    "ID –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è",
    "–¢–µ–º–∞",
    "–í–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞",
    "–î–Ω–∏ –∑–∞–ø—É—Å–∫–∞",
    "–ê–Ω–æ–Ω–∏–º–Ω—ã–π",
    "–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –≤—ã–±–æ—Ä",
    "–í—Ä–µ–º—è (–º–∏–Ω)",
    "–ó–∞–∫—Ä—ã—Ç—å (–¥–∞—Ç–∞)",
    "ID —Ç–æ–ø–∏–∫–∞",
    "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π",
]
VOTING_GUIDE_ROWS = [
    [
        "# –ü–æ–¥—Å–∫–∞–∑–∫–∞",
        "",
        "",
        "–¥–Ω–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é",
        "–î–∞ / –ù–µ—Ç",
        "–î–∞ / –ù–µ—Ç",
        "5‚Äì600",
        "–î–î.–ú–ú.–ì–ì–ì–ì –∏–ª–∏ –î–î.–ú–ú.–ì–ì–ì–ì –ß–ß:–ú–ú",
        "–ß–∏—Å–ª–æ –∏–ª–∏ –æ—Å—Ç–∞–≤–∏—Ç—å –ø—É—Å—Ç—ã–º",
        "",
    ]
]
AUTOMATION_SECTION_HEADER = [
    "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
    "ID —Ç–æ–ø–∏–∫–∞",
    "–ê–Ω–æ–Ω–∏–º–Ω—ã–π",
    "–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –≤—ã–±–æ—Ä",
    "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π",
]
AUTOMATION_SECTION_END_MARKER = "--- END AUTOMATIONS ---"
AUTOMATION_DEFAULT_ROWS = [
    {"key": "BIRTHDAY_NOTIFICATIONS", "name": "–£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –¥–Ω—è—Ö —Ä–æ–∂–¥–µ–Ω–∏—è", "comment": "–ü–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏—è –∏–º–µ–Ω–∏–Ω–Ω–∏–∫–æ–≤"},
    {"key": "GAME_ANNOUNCEMENTS", "name": "–ê–Ω–æ–Ω—Å—ã –∏–≥—Ä", "comment": "–°–æ–æ–±—â–µ–Ω–∏—è —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∏–≥—Ä–µ"},
    {"key": "GAME_POLLS", "name": "–û–ø—Ä–æ—Å—ã –Ω–∞ –∏–≥—Ä—ã", "comment": "–û–ø—Ä–æ—Å –æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –Ω–∞ –∏–≥—Ä—É"},
    {"key": "VOTING_POLLS", "name": "–û–±—â–∏–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è", "comment": "–ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è –∏–∑ –±–ª–æ–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"},
]
LEGACY_VOTING_HEADERS = [
    [
        "–¢–ò–ü (–ì–û–õ–û–°–û–í–ê–ù–ò–Ø)",
        "–ò–î –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è",
        "–ü–æ—Ä—è–¥–æ–∫ / –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ",
        "–¢–µ–º–∞ –∏–ª–∏ –≤–∞—Ä–∏–∞–Ω—Ç",
        "–î–æ–ø. –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (JSON)",
        "–î–Ω–∏ –Ω–µ–¥–µ–ª–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)",
        "URL / —Ä–µ–∑–µ—Ä–≤",
        "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π / —Ä–µ–∑–µ—Ä–≤",
    ],
    [
        "ID –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è",
        "–¢–µ–º–∞",
        "–í–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞",
        "–î–Ω–∏ –∑–∞–ø—É—Å–∫–∞",
        "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã (JSON)",
        "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π",
    ],
]
AUTOMATION_NAME_TO_KEY = {
    row["name"].lower(): row["key"]
    for row in AUTOMATION_DEFAULT_ROWS
}
AUTOMATION_KEY_TO_NAME = {
    row["key"].upper(): row["name"]
    for row in AUTOMATION_DEFAULT_ROWS
}
LEGACY_AUTOMATION_HEADERS = [
    [
        "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
        "ID —Ç–æ–ø–∏–∫–∞",
        "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π",
    ],
]
# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
GOOGLE_SHEETS_CREDENTIALS = os.getenv("GOOGLE_SHEETS_CREDENTIALS")
SPREADSHEET_ID = os.getenv("SPREADSHEET_ID")
TEST_MODE = os.getenv("TEST_MODE", "false").lower() == "true"  # –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Google Sheets
SCOPES = [
    'https://www.googleapis.com/auth/spreadsheets',
    'https://www.googleapis.com/auth/drive'
]

MAX_CONFIG_COLUMNS = max(len(CONFIG_HEADER), len(VOTING_SECTION_HEADER))

class EnhancedDuplicateProtection:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∑–∞—â–∏—Ç—ã –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self):
        self.gc = None
        self.spreadsheet = None
        self.service_worksheet = None
        self.config_worksheet = None
        self._init_google_sheets()
    
    def _init_google_sheets(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Google Sheets"""
        try:
            if not GOOGLE_SHEETS_CREDENTIALS:
                print("‚ùå GOOGLE_SHEETS_CREDENTIALS –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
                return
            
            creds_dict = json.loads(GOOGLE_SHEETS_CREDENTIALS)
            creds = Credentials.from_service_account_info(creds_dict, scopes=SCOPES)
            
            self.gc = gspread.authorize(creds)
            
            if SPREADSHEET_ID:
                self.spreadsheet = self.gc.open_by_key(SPREADSHEET_ID)
                print("‚úÖ Google Sheets –ø–æ–¥–∫–ª—é—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                
                # –ü–æ–ª—É—á–∞–µ–º –ª–∏—Å—Ç "–°–µ—Ä–≤–∏—Å–Ω—ã–π"
                try:
                    self.service_worksheet = self.spreadsheet.worksheet("–°–µ—Ä–≤–∏—Å–Ω—ã–π")
                    print("‚úÖ –õ–∏—Å—Ç '–°–µ—Ä–≤–∏—Å–Ω—ã–π' –ø–æ–¥–∫–ª—é—á–µ–Ω")
                    self._ensure_service_header(self.service_worksheet)
                except gspread.WorksheetNotFound:
                    print("‚ùå –õ–∏—Å—Ç '–°–µ—Ä–≤–∏—Å–Ω—ã–π' –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    print("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ create_service_sheet.py –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ª–∏—Å—Ç–∞")

                try:
                    self.config_worksheet = self.spreadsheet.worksheet(CONFIG_WORKSHEET_NAME)
                    print(f"‚úÖ –õ–∏—Å—Ç '{CONFIG_WORKSHEET_NAME}' –ø–æ–¥–∫–ª—é—á–µ–Ω")
                    self._ensure_config_header()
                except gspread.WorksheetNotFound:
                    print(f"‚ö†Ô∏è –õ–∏—Å—Ç '{CONFIG_WORKSHEET_NAME}' –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞—ë–º –µ–≥–æ")
                    self.config_worksheet = self.spreadsheet.add_worksheet(title=CONFIG_WORKSHEET_NAME, rows=200, cols=len(CONFIG_HEADER))
                    self._ensure_config_header()
            else:
                print("‚ùå SPREADSHEET_ID –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Google Sheets: {e}")
    
    def _ensure_service_header(self, worksheet) -> None:
        if not worksheet:
            return
        try:
            header = worksheet.row_values(1)
            if not header:
                worksheet.update(f'A1:{END_COLUMN_LETTER}1', [SERVICE_HEADER])
                return
            desired_length = len(SERVICE_HEADER)
            if len(header) < desired_length:
                header.extend([""] * (desired_length - len(header)))
            updated = False
            for index, expected in enumerate(SERVICE_HEADER):
                if not header[index]:
                    header[index] = expected
                    updated = True
            if updated:
                worksheet.update(f'A1:{END_COLUMN_LETTER}1', [header])
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –ª–∏—Å—Ç–∞: {e}")

    def _ensure_config_header(self) -> None:
        worksheet = self.config_worksheet
        if not worksheet:
            return
        try:
            header = worksheet.row_values(1)
            if not header:
                worksheet.update(f'A1:{chr(ord("A") + len(CONFIG_HEADER) - 1)}1', [CONFIG_HEADER])
                return
            desired_length = len(CONFIG_HEADER)
            if len(header) < desired_length:
                header.extend([""] * (desired_length - len(header)))
            updated = False
            for index, expected in enumerate(CONFIG_HEADER):
                if not header[index]:
                    header[index] = expected
                    updated = True
            if updated:
                worksheet.update(f'A1:{chr(ord("A") + len(CONFIG_HEADER) - 1)}1', [header])
            self._ensure_voting_section_structure(worksheet)
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ª–∏—Å—Ç–∞ '{CONFIG_WORKSHEET_NAME}': {e}")
 
    def _ensure_voting_section_structure(self, worksheet) -> None:
        """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ä–∞–∑–¥–µ–ª–∞ –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–π"""
        try:
            total_columns = MAX_CONFIG_COLUMNS
            padded_header = VOTING_SECTION_HEADER + [""] * (total_columns - len(VOTING_SECTION_HEADER))

            all_data = worksheet.get_all_values()
            end_row_index: Optional[int] = None
            end_marker_value: Optional[str] = None
            for idx, row in enumerate(all_data, start=1):
                if row and row[0].strip() in CONFIG_SECTION_END_MARKERS:
                    end_row_index = idx
                    end_marker_value = row[0].strip()
                    break

            if end_row_index is None:
                end_row_index = len(all_data) + 1
                worksheet.append_row(
                    [DEFAULT_END_MARKER] + [""] * (total_columns - 1),
                    value_input_option="USER_ENTERED",
                )
                all_data.append([DEFAULT_END_MARKER])
            elif end_marker_value and end_marker_value != DEFAULT_END_MARKER:
                worksheet.update(f"A{end_row_index}", [[DEFAULT_END_MARKER]])
                all_data[end_row_index - 1][0] = DEFAULT_END_MARKER

            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
            all_data = worksheet.get_all_values()

            header_row_index: Optional[int] = None
            for idx in range(end_row_index + 1, len(all_data) + 1):
                row = all_data[idx - 1]
                normalized = [cell.strip() for cell in row]
                if not any(normalized):
                    continue
                if normalized[0].upper() == VOTING_SECTION_END_MARKER.upper():
                    break
                legacy_header_detected = any(
                    normalized[:len(legacy)] == [cell.strip() for cell in legacy]
                    for legacy in LEGACY_VOTING_HEADERS
                )
                if legacy_header_detected or normalized[:len(VOTING_SECTION_HEADER)] == VOTING_SECTION_HEADER or any(
                    "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã (JSON)" in cell for cell in normalized
                ):
                    header_row_index = idx
                    break

            if header_row_index is None:
                insert_index = end_row_index + 1
                if insert_index - 1 < len(all_data):
                    candidate = all_data[insert_index - 1]
                    if any(cell.strip() for cell in candidate):
                        insert_index += 1
                worksheet.insert_row(
                    padded_header,
                    insert_index,
                    value_input_option="USER_ENTERED",
                )
                header_row_index = insert_index
                all_data = worksheet.get_all_values()
            else:
                worksheet.update(
                    f"A{header_row_index}:{chr(ord('A') + total_columns - 1)}{header_row_index}",
                    [padded_header],
                )
                all_data[header_row_index - 1] = padded_header

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–∞—Ä–∫–µ—Ä–∞ –∫–æ–Ω—Ü–∞ –±–ª–æ–∫–∞ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–π
            has_voting_end_marker = any(
                row and row[0].strip().upper() == VOTING_SECTION_END_MARKER.upper()
                for row in worksheet.get_all_values()
            )
            if not has_voting_end_marker:
                worksheet.append_row(
                    [VOTING_SECTION_END_MARKER] + [""] * (total_columns - 1),
                    value_input_option="USER_ENTERED",
                )

            guide_exists = False
            for row in worksheet.get_all_values():
                if row and isinstance(row[0], str) and row[0].strip().startswith("# –ü–æ–¥—Å–∫–∞–∑–∫–∞"):
                    guide_exists = True
                    break
            if not guide_exists:
                for guide_row in VOTING_GUIDE_ROWS:
                    padded_instruction = guide_row + [""] * (total_columns - len(guide_row))
                    worksheet.append_row(
                        padded_instruction,
                        value_input_option="USER_ENTERED",
                    )
            self._ensure_automation_section_structure(worksheet)
        except Exception as error:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∞–∑–¥–µ–ª–∞ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–π: {error}")

    def _ensure_automation_section_structure(self, worksheet) -> None:
        """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ä–∞–∑–¥–µ–ª–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
        try:
            total_columns = MAX_CONFIG_COLUMNS
            padded_header = AUTOMATION_SECTION_HEADER + [""] * (total_columns - len(AUTOMATION_SECTION_HEADER))
            all_data = worksheet.get_all_values()

            header_row_index: Optional[int] = None
            for idx, row in enumerate(all_data, start=1):
                normalized = [cell.strip() for cell in row]
                if not any(normalized):
                    continue
                if normalized[:len(AUTOMATION_SECTION_HEADER)] == AUTOMATION_SECTION_HEADER:
                    header_row_index = idx
                    break
                for legacy in LEGACY_AUTOMATION_HEADERS:
                    if normalized[:len(legacy)] == [cell.strip() for cell in legacy]:
                        header_row_index = idx
                        break
                if header_row_index is not None:
                    break

            if header_row_index is None:
                worksheet.append_row(
                    padded_header,
                    value_input_option="USER_ENTERED",
                )
                all_data = worksheet.get_all_values()
                header_row_index = len(all_data)
            else:
                worksheet.update(
                    f"A{header_row_index}:{chr(ord('A') + total_columns - 1)}{header_row_index}",
                    [padded_header],
                )
                all_data[header_row_index - 1] = padded_header

            existing_entries: Dict[str, Dict[str, str]] = {}
            for row in all_data[header_row_index:]:
                if not row:
                    continue
                label = (row[0] or "").strip()
                if (
                    not label
                    or label == AUTOMATION_SECTION_HEADER[0]
                    or label.upper() == AUTOMATION_SECTION_END_MARKER.upper()
                    or label.startswith("#")
                    or label.upper() == "–ö–û–î"
                ):
                    continue
                mapped_key = AUTOMATION_NAME_TO_KEY.get(label.lower())
                key_upper = mapped_key.upper() if mapped_key else label.upper()
                display_name = AUTOMATION_KEY_TO_NAME.get(key_upper, label)
                topic_value = row[1] if len(row) > 1 else ""
                anon_value = row[2] if len(row) > 2 else ""
                multiple_value = row[3] if len(row) > 3 else ""
                comment_value = row[4] if len(row) > 4 else ""
                existing_entries[key_upper] = {
                    "label": display_name,
                    "topic": topic_value,
                    "anon": anon_value,
                    "multiple": multiple_value,
                    "comment": comment_value,
                }

            rows_to_write: List[List[str]] = []
            for default in AUTOMATION_DEFAULT_ROWS:
                key_upper = default["key"].upper()
                existing = existing_entries.pop(key_upper, None)
                label = default["name"]
                topic_value = ""
                anon_value = ""
                multiple_value = ""
                comment_value = default.get("comment", "")
                if existing:
                    label = existing.get("label") or label
                    topic_value = existing.get("topic", "")
                    anon_value = existing.get("anon", "")
                    multiple_value = existing.get("multiple", "")
                    comment_value = existing.get("comment", "") or comment_value
                rows_to_write.append([label, topic_value, anon_value, multiple_value, comment_value])

            for key_upper, entry in existing_entries.items():
                rows_to_write.append([
                    entry.get("label") or key_upper,
                    entry.get("topic", ""),
                    entry.get("anon", ""),
                    entry.get("multiple", ""),
                    entry.get("comment", ""),
                ])

            rows_to_write.append([AUTOMATION_SECTION_END_MARKER] + [""] * (len(AUTOMATION_SECTION_HEADER) - 1))

            end_marker_row_index: Optional[int] = None
            for idx in range(header_row_index + 1, len(all_data) + 1):
                row = all_data[idx - 1]
                if row and (row[0] or "").strip().upper() == AUTOMATION_SECTION_END_MARKER.upper():
                    end_marker_row_index = idx

            existing_range_length = 0
            if end_marker_row_index:
                existing_range_length = end_marker_row_index - header_row_index
            else:
                existing_range_length = len(rows_to_write)

            range_length = max(existing_range_length, len(rows_to_write))
            rows_padded: List[List[str]] = []
            for idx in range(range_length):
                if idx < len(rows_to_write):
                    base_row = rows_to_write[idx]
                else:
                    base_row = [""] * len(AUTOMATION_SECTION_HEADER)
                padded = base_row + [""] * (total_columns - len(base_row))
                rows_padded.append(padded)

            worksheet.update(
                f"A{header_row_index + 1}:{chr(ord('A') + total_columns - 1)}{header_row_index + range_length}",
                rows_padded,
                value_input_option="USER_ENTERED",
            )
        except Exception as error:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∞–∑–¥–µ–ª–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {error}")

    @staticmethod
    def _normalize_cell_text(value: Any) -> str:
        if value is None:
            return ""
        if isinstance(value, str):
            return value.strip()
        return str(value).strip()

    @staticmethod
    def _try_parse_int(value: Any) -> Optional[int]:
        if value in (None, ""):
            return None
        try:
            return int(str(value).strip())
        except (TypeError, ValueError):
            return None

    @staticmethod
    def _parse_weekday_value(value: Any) -> Optional[int]:
        text = EnhancedDuplicateProtection._normalize_cell_text(value).lower()
        if not text:
            return None
        mapping = {
            "0": 0,
            "1": 1,
            "2": 2,
            "3": 3,
            "4": 4,
            "5": 5,
            "6": 6,
            "mon": 0,
            "tue": 1,
            "wed": 2,
            "thu": 3,
            "fri": 4,
            "sat": 5,
            "sun": 6,
            "monday": 0,
            "tuesday": 1,
            "wednesday": 2,
            "thursday": 3,
            "friday": 4,
            "saturday": 5,
            "sunday": 6,
            "–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫": 0,
            "–≤—Ç–æ—Ä–Ω–∏–∫": 1,
            "—Å—Ä–µ–¥–∞": 2,
            "—á–µ—Ç–≤–µ—Ä–≥": 3,
            "–ø—è—Ç–Ω–∏—Ü–∞": 4,
            "—Å—É–±–±–æ—Ç–∞": 5,
            "–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ": 6,
            "–ø–Ω": 0,
            "–≤—Ç": 1,
            "—Å—Ä": 2,
            "—á—Ç": 3,
            "–ø—Ç": 4,
            "—Å–±": 5,
            "–≤—Å": 6,
        }
        return mapping.get(text)

    @staticmethod
    def _parse_bool_value(value: Any) -> Optional[bool]:
        text = EnhancedDuplicateProtection._normalize_cell_text(value).lower()
        if not text:
            return None
        truthy = {"true", "1", "yes", "y", "–¥–∞", "–¥", "–∏—Å—Ç–∏–Ω–∞", "+", "on"}
        falsy = {"false", "0", "no", "n", "–Ω–µ—Ç", "–Ω", "–ª–æ–∂—å", "-", "off"}
        if text in truthy:
            return True
        if text in falsy:
            return False
        return None

    def _get_service_worksheet(self, raw: bool = False):
        """–ü–æ–ª—É—á–∞–µ—Ç –ª–∏—Å—Ç '–°–µ—Ä–≤–∏—Å–Ω—ã–π'"""
        if not self.spreadsheet:
            print("‚ùå Google Sheets –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return None
            
        if not self.service_worksheet:
            try:
                self.service_worksheet = self.spreadsheet.worksheet("–°–µ—Ä–≤–∏—Å–Ω—ã–π")
            except gspread.WorksheetNotFound:
                print("‚ùå –õ–∏—Å—Ç '–°–µ—Ä–≤–∏—Å–Ω—ã–π' –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return None
        
        if not raw:
            self._ensure_service_header(self.service_worksheet)
        return self.service_worksheet

    def _create_unique_key(self, data_type: str, identifier: str, **kwargs) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –∑–∞–ø–∏—Å–∏"""
        # –ë–∞–∑–æ–≤—ã–π –∫–ª—é—á
        base_key = f"{data_type}_{identifier}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å TEST_ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
        if TEST_MODE:
            base_key = f"TEST_{base_key}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
        if kwargs:
            additional = "_".join([f"{k}_{v}" for k, v in sorted(kwargs.items())])
            base_key = f"{base_key}_{additional}"
        
        return base_key
    
    def _get_current_datetime(self) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è –≤ –º–æ—Å–∫–æ–≤—Å–∫–æ–º —á–∞—Å–æ–≤–æ–º –ø–æ—è—Å–µ"""
        now = get_moscow_time()
        return now.strftime('%d.%m.%Y %H:%M')
    
    def check_duplicate(self, data_type: str, identifier: str, **kwargs) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–∞"""
        worksheet = self._get_service_worksheet()
        if not worksheet:
            return {'exists': False, 'error': '–õ–∏—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω'}
        
        try:
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á
            unique_key = self._create_unique_key(data_type, identifier, **kwargs)
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            all_data = worksheet.get_all_values()
            
            # –ò—â–µ–º –¥—É–±–ª–∏–∫–∞—Ç –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∫–ª—é—á—É (–∫–æ–ª–æ–Ω–∫–∞ C) –ò –ø–æ —Ç–∏–ø—É –¥–∞–Ω–Ω—ã—Ö (–∫–æ–ª–æ–Ω–∫–∞ A)
            for i, row in enumerate(all_data):
                if (len(row) >= 3 and 
                    row[0].upper() == data_type.upper() and 
                    row[2] == unique_key):
                    return {
                        'exists': True,
                        'row': i + 1,
                        'data': row,
                        'unique_key': unique_key
                    }
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –∏—â–µ–º –ø–æ —Ç–∏–ø—É –∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É
            for i, row in enumerate(all_data):
                if (len(row) >= 3 and 
                    row[0].upper() == data_type.upper() and 
                    identifier in row[2]):
                    return {
                        'exists': True,
                        'row': i + 1,
                        'data': row,
                        'unique_key': row[2],
                        'reason': '–ù–∞–π–¥–µ–Ω –ø–æ —Ç–∏–ø—É –∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É'
                    }
            
            return {'exists': False, 'unique_key': unique_key}
            
        except Exception as e:
            return {'exists': False, 'error': str(e)}
    
    def add_record(
        self,
        data_type: str,
        identifier: str,
        status: str = "–ê–ö–¢–ò–í–ï–ù",
        additional_data: str = "",
        game_link: str = "",
        comp_id: Optional[int] = None,
        team_id: Optional[int] = None,
        alt_name: str = "",
        settings: str = "",
        game_id: Optional[int] = None,
        game_date: str = "",
        game_time: str = "",
        arena: str = "",
        team_a_id: Optional[int] = None,
        team_b_id: Optional[int] = None,
        **kwargs,
    ) -> Dict[str, Any]:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –≤ —Å–µ—Ä–≤–∏—Å–Ω—ã–π –ª–∏—Å—Ç"""
        worksheet = self._get_service_worksheet()
        if not worksheet:
            return {'success': False, 'error': '–õ–∏—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω'}
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç
            duplicate_check = self.check_duplicate(data_type, identifier, **kwargs)
            
            if duplicate_check.get('exists'):
                return {
                    'success': False,
                    'error': '–î—É–±–ª–∏–∫–∞—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç',
                    'duplicate_info': duplicate_check
                }
            
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á
            unique_key = duplicate_check.get('unique_key') or self._create_unique_key(data_type, identifier, **kwargs)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É
            current_datetime = self._get_current_datetime()
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
            new_record = [
                data_type.upper(),
                current_datetime,
                unique_key,
                status,
                additional_data,
                game_link,
                str(comp_id) if comp_id is not None else "",
                str(team_id) if team_id is not None else "",
                alt_name,
                settings,
                str(game_id) if game_id is not None else "",
                game_date,
                game_time,
                arena,
                str(team_a_id) if team_a_id is not None else "",
                str(team_b_id) if team_b_id is not None else "",
            ]
            
            if len(new_record) < len(SERVICE_HEADER):
                new_record.extend([""] * (len(SERVICE_HEADER) - len(new_record)))
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –Ω–∞—á–∞–ª–æ (–ø–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º)
            worksheet.insert_row(new_record, index=2)
            
            print(f"‚úÖ –ó–∞–ø–∏—Å—å –¥–æ–±–∞–≤–ª–µ–Ω–∞: {data_type} - {identifier}")
            
            return {
                'success': True,
                'unique_key': unique_key,
                'row': 2
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def find_game_link_for_today(self, team1: str, team2: str) -> Optional[str]:
        """–ò—â–µ—Ç —Å—Å—ã–ª–∫—É –Ω–∞ –∏–≥—Ä—É –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–π –¥–∞—Ç—ã"""
        worksheet = self._get_service_worksheet()
        if not worksheet:
            print("‚ùå –õ–∏—Å—Ç '–°–µ—Ä–≤–∏—Å–Ω—ã–π' –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
        
        try:
            from datetime_utils import get_moscow_time
            today = get_moscow_time().strftime('%d.%m.%Y')
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            all_data = worksheet.get_all_values()
            
            print(f"üîç –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –∏–≥—Ä—É –¥–ª—è {today}: {team1} vs {team2}")
            
            # –ò—â–µ–º –∑–∞–ø–∏—Å–∏ —Ç–∏–ø–∞ –ê–ù–û–ù–°_–ò–ì–†–ê –∑–∞ —Å–µ–≥–æ–¥–Ω—è
            for row in all_data:
                if (len(row) > LINK_COL and 
                    row[TYPE_COL] == "–ê–ù–û–ù–°_–ò–ì–†–ê" and 
                    today in row[DATE_COL] and  # –î–∞—Ç–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ B
                    row[LINK_COL]):  # –°—Å—ã–ª–∫–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ F
                    
                    # –ë–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–º–∞–Ω–¥
                    unique_key = row[2].lower()
                    team1_lower = team1.lower()
                    team2_lower = team2.lower()
                    
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                    def _normalize_team_name(name: str) -> str:
                        import re as _re
                        return _re.sub(r"[\W_]+", "", name.lower())

                    def _build_variants(name: str) -> Set[str]:
                        variants: Set[str] = set()
                        if not name:
                            return variants
                        lowered = name.lower()
                        variants.add(lowered)
                        variants.add(_normalize_team_name(name))
                        for part in lowered.replace('-', ' ').replace('_', ' ').split():
                            if len(part) > 2:
                                variants.add(part)
                        return {variant for variant in variants if variant}

                    team1_variants = _build_variants(team1)
                    team2_variants = _build_variants(team2)
                    unique_key_lower = unique_key.lower()
                    unique_key_normalized = _normalize_team_name(unique_key)

                    def _contains_variant(variants: Set[str]) -> bool:
                        for variant in variants:
                            if len(variant) <= 2:
                                continue
                            if variant in unique_key_lower or variant in unique_key_normalized:
                                return True
                        return False

                    team1_found = _contains_variant(team1_variants)
                    team2_found = _contains_variant(team2_variants)

                    # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –æ–±–µ –∫–æ–º–∞–Ω–¥—ã ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Å—ã–ª–∫—É
                    if team1_found and team2_found:
                        game_link = row[LINK_COL]
                        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Ç–æ—á–Ω–∞—è —Å—Å—ã–ª–∫–∞ –≤ —Å–µ—Ä–≤–∏—Å–Ω–æ–º –ª–∏—Å—Ç–µ: {game_link}")
                        print(f"   –ü–æ –∫–ª—é—á—É: {row[2]}")
                        print(f"   –î–ª—è –∫–æ–º–∞–Ω–¥: {team1} vs {team2}")
                        return game_link
            
            print(f"‚ùå –°—Å—ã–ª–∫–∞ –Ω–∞ –∏–≥—Ä—É –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Å–µ—Ä–≤–∏—Å–Ω–æ–º –ª–∏—Å—Ç–µ")
            return None
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–∫–∏ –≤ —Å–µ—Ä–≤–∏—Å–Ω–æ–º –ª–∏—Å—Ç–µ: {e}")
            return None
    
    def update_record_status(self, unique_key: str, new_status: str) -> Dict[str, Any]:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞–ø–∏—Å–∏"""
        worksheet = self._get_service_worksheet()
        if not worksheet:
            return {'success': False, 'error': '–õ–∏—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω'}
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            all_data = worksheet.get_all_values()
            
            # –ò—â–µ–º –∑–∞–ø–∏—Å—å –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∫–ª—é—á—É
            for i, row in enumerate(all_data):
                if len(row) >= 3 and row[2] == unique_key:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å (–∫–æ–ª–æ–Ω–∫–∞ D)
                    worksheet.update(values=[[new_status]], range_name=f'D{i+1}')
                    
                    print(f"‚úÖ –°—Ç–∞—Ç—É—Å –æ–±–Ω–æ–≤–ª–µ–Ω: {unique_key} -> {new_status}")
                    
                    return {
                        'success': True,
                        'row': i + 1,
                        'old_status': row[3] if len(row) > 3 else '',
                        'new_status': new_status
                    }
            
            return {'success': False, 'error': '–ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def get_records_by_type(self, data_type: str) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –∑–∞–ø–∏—Å–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞"""
        worksheet = self._get_service_worksheet()
        if not worksheet:
            return []
        
        try:
            all_data = worksheet.get_all_values()
            records = []
            
            for i, row in enumerate(all_data):
                if len(row) >= 1 and row[0].upper() == data_type.upper():
                    records.append({
                        'row': i + 1,
                        'type': row[TYPE_COL] if len(row) > TYPE_COL else '',
                        'date': row[DATE_COL] if len(row) > DATE_COL else '',
                        'unique_key': row[KEY_COL] if len(row) > KEY_COL else '',
                        'status': row[STATUS_COL] if len(row) > STATUS_COL else '',
                        'additional_data': row[ADDITIONAL_DATA_COL] if len(row) > ADDITIONAL_DATA_COL else '',
                        'link': row[LINK_COL] if len(row) > LINK_COL else '',
                        'comp_id': row[COMP_ID_COL] if len(row) > COMP_ID_COL else '',
                        'team_id': row[TEAM_ID_COL] if len(row) > TEAM_ID_COL else '',
                        'alt_name': row[ALT_NAME_COL] if len(row) > ALT_NAME_COL else '',
                        'settings': row[CONFIG_COL] if len(row) > CONFIG_COL else '',
                        'game_id': row[GAME_ID_COL] if len(row) > GAME_ID_COL else '',
                        'game_date': row[GAME_DATE_COL] if len(row) > GAME_DATE_COL else '',
                        'game_time': row[GAME_TIME_COL] if len(row) > GAME_TIME_COL else '',
                        'arena': row[ARENA_COL] if len(row) > ARENA_COL else '',
                        'team_a_id': row[TEAM_A_ID_COL] if len(row) > TEAM_A_ID_COL else '',
                        'team_b_id': row[TEAM_B_ID_COL] if len(row) > TEAM_B_ID_COL else ''
                    })
            
            return records
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–ø–∏—Å–µ–π: {e}")
            return []
    
    def get_game_record(self, data_type: str, game_id: Any) -> Optional[Dict[str, Any]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–ø–∏—Å—å –æ–± –∏–≥—Ä–µ –ø–æ GameID"""
        worksheet = self._get_service_worksheet()
        if not worksheet:
            return None
        
        try:
            game_id_str = str(game_id)
            all_data = worksheet.get_all_values()
            for row_index, row in enumerate(all_data[1:], start=2):
                if len(row) <= max(GAME_ID_COL, TYPE_COL):
                    continue
                if row[TYPE_COL].upper() != data_type.upper():
                    continue
                if row[GAME_ID_COL] == game_id_str:
                    return {
                        'row': row_index,
                        'type': row[TYPE_COL],
                        'date': row[DATE_COL],
                        'unique_key': row[KEY_COL],
                        'status': row[STATUS_COL],
                        'additional_data': row[ADDITIONAL_DATA_COL],
                        'link': row[LINK_COL],
                        'comp_id': row[COMP_ID_COL],
                        'team_id': row[TEAM_ID_COL],
                        'alt_name': row[ALT_NAME_COL],
                        'settings': row[CONFIG_COL],
                        'game_id': row[GAME_ID_COL],
                        'game_date': row[GAME_DATE_COL],
                        'game_time': row[GAME_TIME_COL],
                        'arena': row[ARENA_COL],
                        'team_a_id': row[TEAM_A_ID_COL],
                        'team_b_id': row[TEAM_B_ID_COL],
                    }
            return None
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∑–∞–ø–∏—Å–∏ –∏–≥—Ä—ã: {e}")
            return None
    
    def upsert_game_record(
        self,
        data_type: str,
        identifier: str,
        status: str,
        additional_data: str,
        game_link: str,
        comp_id: Optional[int],
        team_id: Optional[int],
        alt_name: str,
        settings: str,
        game_id: Any,
        game_date: str,
        game_time: str,
        arena: str,
        team_a_id: Optional[int],
        team_b_id: Optional[int],
        **kwargs,
    ) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∑–∞–ø–∏—Å—å –æ–± –∏–≥—Ä–µ"""
        worksheet = self._get_service_worksheet()
        if not worksheet:
            return {'success': False, 'error': '–õ–∏—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω'}
        
        try:
            game_id_str = str(game_id) if game_id is not None else ""
            existing = self.get_game_record(data_type, game_id_str) if game_id_str else None
            unique_key = existing.get('unique_key') if existing else self._create_unique_key(data_type, identifier, **kwargs)
            current_datetime = self._get_current_datetime()
            
            row_values = [
                data_type.upper(),
                current_datetime,
                unique_key,
                status,
                additional_data,
                game_link,
                str(comp_id) if comp_id is not None else "",
                str(team_id) if team_id is not None else "",
                alt_name,
                settings,
                game_id_str,
                game_date,
                game_time,
                arena,
                str(team_a_id) if team_a_id is not None else "",
                str(team_b_id) if team_b_id is not None else "",
            ]
            
            if existing:
                row_index = existing['row']
                worksheet.update(f"A{row_index}:{END_COLUMN_LETTER}{row_index}", [row_values])
                print(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∞ –∑–∞–ø–∏—Å—å {data_type} –¥–ª—è GameID {game_id_str}")
                return {'success': True, 'action': 'updated', 'row': row_index}
            
            result = self.add_record(
                data_type=data_type,
                identifier=identifier,
                status=status,
                additional_data=additional_data,
                game_link=game_link,
                comp_id=comp_id,
                team_id=team_id,
                alt_name=alt_name,
                settings=settings,
                game_id=game_id,
                game_date=game_date,
                game_time=game_time,
                arena=arena,
                team_a_id=team_a_id,
                team_b_id=team_b_id,
                **kwargs,
            )
            result['action'] = 'inserted' if result.get('success') else 'error'
            return result
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def get_active_records(self, data_type: str) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞"""
        all_records = self.get_records_by_type(data_type)
        return [record for record in all_records if record.get('status') == '–ê–ö–¢–ò–í–ï–ù']
    
    def cleanup_old_records(self, data_type: str, days_old: int = 30) -> Dict[str, Any]:
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞"""
        worksheet = self._get_service_worksheet()
        if not worksheet:
            return {'success': False, 'error': '–õ–∏—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω'}
        
        try:
            all_data = worksheet.get_all_values()
            current_datetime = get_moscow_time()
            rows_to_delete: List[int] = []
            
            for row_index, row in enumerate(all_data[1:], start=2):
                if len(row) <= max(DATE_COL, TYPE_COL):
                    continue
                
                row_type = row[TYPE_COL].upper() if len(row) > TYPE_COL else ''
                if row_type != data_type.upper():
                    continue
                
                date_value = row[DATE_COL]
                if not date_value:
                    continue
                
                try:
                    from datetime import datetime as dt
                    record_date = dt.strptime(date_value, '%d.%m.%Y %H:%M')
                except ValueError:
                    continue
                
                record_date = record_date.replace(tzinfo=current_datetime.tzinfo)
                age_days = (current_datetime - record_date).days
                
                if age_days > days_old:
                    rows_to_delete.append(row_index)
            
            for row_index in reversed(rows_to_delete):
                worksheet.delete_rows(row_index)
            
            print(f"‚úÖ –û—á–∏—â–µ–Ω–æ {len(rows_to_delete)} —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π —Ç–∏–ø–∞ {data_type}")
            
            return {
                'success': True,
                'cleaned_count': len(rows_to_delete),
                'data_type': data_type
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å–µ–º —Ç–∏–ø–∞–º –∑–∞–ø–∏—Å–µ–π"""
        worksheet = self._get_service_worksheet()
        if not worksheet:
            return {'error': '–õ–∏—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω'}
        
        try:
            all_data = worksheet.get_all_values()
            stats = {}
            
            for row in all_data:
                if len(row) >= 1 and row[0]:
                    data_type = row[0]
                    if data_type.startswith('===') or data_type.startswith('–¢–ò–ü –î–ê–ù–ù–´–•'):
                        continue
                    
                    if data_type not in stats:
                        stats[data_type] = {'total': 0, 'active': 0, 'completed': 0}
                    
                    stats[data_type]['total'] += 1
                    
                    if len(row) >= 4:
                        status = row[3]
                        if status == '–ê–ö–¢–ò–í–ï–ù':
                            stats[data_type]['active'] += 1
                        elif status in ['–ó–ê–í–ï–†–®–ï–ù', '–û–¢–ü–†–ê–í–õ–ï–ù', '–û–ë–†–ê–ë–û–¢–ê–ù', '–û–¢–ü–†–ê–í–õ–ï–ù–û']:
                            stats[data_type]['completed'] += 1
            
            return stats
            
        except Exception as e:
            return {'error': str(e)}

    def cleanup_expired_records(self, max_age_days: int = 30) -> Dict[str, Any]:
        """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ä—à–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–Ω–µ–π"""
        worksheet = self._get_service_worksheet()
        if not worksheet:
            return {'success': False, 'error': '–õ–∏—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω'}
        
        try:
            all_data = worksheet.get_all_values()
            if not all_data:
                return {'success': True, 'cleaned_count': 0, 'details': []}
            
            current_datetime = get_moscow_time()
            rows_to_delete: List[Tuple[int, str]] = []
            
            for row_index, row in enumerate(all_data[1:], start=2):
                if len(row) <= DATE_COL:
                    continue
                
                date_value = row[DATE_COL]
                if not date_value:
                    continue
                
                try:
                    from datetime import datetime as dt
                    record_date = dt.strptime(date_value, '%d.%m.%Y %H:%M')
                except ValueError:
                    continue
                
                record_date = record_date.replace(tzinfo=current_datetime.tzinfo)
                age_days = (current_datetime - record_date).days
                
                if age_days > max_age_days:
                    record_type = row[TYPE_COL] if len(row) > TYPE_COL else ''
                    rows_to_delete.append((row_index, record_type))
            
            for row_index, _ in reversed(rows_to_delete):
                worksheet.delete_rows(row_index)
            
            print(f"‚úÖ –û—á–∏—â–µ–Ω–æ {len(rows_to_delete)} –∑–∞–ø–∏—Å–µ–π —Å—Ç–∞—Ä—à–µ {max_age_days} –¥–Ω–µ–π")
            
            return {
                'success': True,
                'cleaned_count': len(rows_to_delete),
                'details': rows_to_delete
            }
        except Exception as e:
            return {'success': False, 'error': str(e)}

    @staticmethod
    def _parse_ids(cell_value: str) -> List[int]:
        """–ü–∞—Ä—Å–∏—Ç —á–∏—Å–ª–æ–≤—ã–µ ID –∏–∑ –∑–Ω–∞—á–µ–Ω–∏—è —è—á–µ–π–∫–∏"""
        if not cell_value:
            return []
        
        normalized = cell_value.replace('\n', ',').replace(';', ',')
        parts = [part.strip() for part in normalized.split(',') if part.strip()]
        ids: List[int] = []
        for part in parts:
            matches = re.findall(r'\d+', part)
            for match in matches:
                try:
                    ids.append(int(match))
                except ValueError:
                    continue
        return ids
    
    @staticmethod
    def _parse_json_config(cell_value: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç JSON –∏–∑ —è—á–µ–π–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        if not cell_value:
            return {}
        if isinstance(cell_value, dict):
            return cell_value
        try:
            return json.loads(cell_value)
        except (json.JSONDecodeError, TypeError) as e:
            print(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –ª–∏—Å—Ç–∞: {e}")
            return {}

    def get_full_config(self) -> Dict[str, Any]:
        config_data = self._read_config_from_config_sheet()
        if config_data.get('has_data'):
            return config_data['payload']

        print(f"‚ö†Ô∏è –õ–∏—Å—Ç '{CONFIG_WORKSHEET_NAME}' –ø—É—Å—Ç ‚Äî —á–∏—Ç–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ '–°–µ—Ä–≤–∏—Å–Ω–æ–≥–æ' (–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º)")
        return self._read_config_from_service_sheet()

    def _read_config_from_config_sheet(self) -> Dict[str, Any]:
        worksheet = self.config_worksheet
        payload = {
            'comp_ids': set(),
            'team_ids': set(),
            'teams': {},
            'training_polls': [],
            'fallback_sources': [],
            'voting_polls': [],
            'automation_topics': {},
        }
        if not worksheet:
            return {'has_data': False, 'payload': payload}

        try:
            all_data = worksheet.get_all_values()
            if not all_data or len(all_data) <= 1:
                return {'has_data': False, 'payload': payload}

            comp_ids_set: Set[int] = set()
            team_ids_set: Set[int] = set()
            teams: Dict[int, Dict[str, Any]] = {}
            training_polls: List[Dict[str, Any]] = []
            fallback_sources: List[Dict[str, Any]] = []
            voting_entries: Dict[str, Dict[str, Any]] = {}
            automation_topics: Dict[str, Dict[str, Any]] = {}
            found_end_marker = False

            required_len = len(CONFIG_HEADER)

            for row in all_data[1:]:
                if not row or len(row) < 1:
                    continue

                row_extended = list(row)
                if len(row_extended) < required_len:
                    row_extended.extend([""] * (required_len - len(row_extended)))

                row_type = self._normalize_cell_text(row_extended[0]) if row_extended else ""
                normalized_type = row_type.upper()

                if not found_end_marker and normalized_type in CONFIG_SECTION_END_MARKERS:
                    found_end_marker = True
                    continue

                if found_end_marker and normalized_type == VOTING_SECTION_END_MARKER:
                    break

                if not found_end_marker:
                    comp_id_cell = row_extended[1]
                    team_id_cell = row_extended[2]
                    alt_name = self._normalize_cell_text(row_extended[3])
                    settings_json_cell = row_extended[4]
                    weekday_cell = row_extended[5]
                    fallback_url = row_extended[6]
                    fallback_name = row_extended[7]

                    row_comp_ids = self._parse_ids(comp_id_cell)
                    row_team_ids = self._parse_ids(team_id_cell)
                    config_payload = self._parse_json_config(settings_json_cell)

                    if not normalized_type:
                        if row_team_ids:
                            normalized_type = "CONFIG_TEAM"
                        elif row_comp_ids:
                            normalized_type = "CONFIG_COMP"

                    if normalized_type in {"CONFIG_COMP", "COMP_CONFIG"}:
                        comp_ids_set.update(row_comp_ids)
                    elif normalized_type in {"CONFIG_TEAM", "TEAM_CONFIG"}:
                        comp_ids_set.update(row_comp_ids)
                        for team_id in row_team_ids:
                            team_ids_set.add(team_id)
                            team_entry = teams.setdefault(
                                team_id,
                                {"alt_name": None, "comp_ids": set(), "metadata": {}},
                            )
                            if alt_name:
                                team_entry["alt_name"] = alt_name
                            if row_comp_ids:
                                team_entry["comp_ids"].update(row_comp_ids)
                            if config_payload:
                                team_entry["metadata"].update(config_payload)
                    elif normalized_type in {"TRAINING_POLL", "TRAINING_CONFIG"}:
                        training_entry = {
                            "title": config_payload.get("title") or alt_name,
                            "weekday": config_payload.get("weekday"),
                            "time": config_payload.get("time"),
                            "location": config_payload.get("location"),
                            "topic_id": config_payload.get("topic_id"),
                            "metadata": config_payload,
                        }
                        training_polls.append(training_entry)
                    elif normalized_type in {"FALLBACK", "FALLBACK_SOURCE", "FALLBACK_CONFIG"}:
                        fallback_entry = {
                            "name": fallback_name or alt_name,
                            "url": fallback_url,
                            "metadata": config_payload,
                        }
                        if fallback_entry["url"] or fallback_entry["name"]:
                            fallback_sources.append(fallback_entry)
                    else:
                        # Unknown types before the separator are ignored to keep backward compatibility
                        continue
                    continue

                # Everything below this point belongs to the voting configuration section
                poll_id_cell = row_extended[0]
                topic_cell = self._normalize_cell_text(row_extended[1])
                option_cell = self._normalize_cell_text(row_extended[2])
                weekday_cell = row_extended[3]
                if len(row_extended) < len(VOTING_SECTION_HEADER):
                    row_extended.extend([""] * (len(VOTING_SECTION_HEADER) - len(row_extended)))
                anon_cell = row_extended[4]
                multiple_cell = row_extended[5]
                open_period_cell = row_extended[6]
                close_date_cell = row_extended[7]
                topic_id_cell = self._normalize_cell_text(row_extended[8]) if len(row_extended) > 8 else ""
                comment_cell = self._normalize_cell_text(row_extended[9]) if len(row_extended) > 9 else ""
                header_candidate = [cell.strip() for cell in row_extended[:len(VOTING_SECTION_HEADER)]]
                if header_candidate == VOTING_SECTION_HEADER or any(
                    header_candidate[:len(legacy)] == [value.strip() for value in legacy[:len(header_candidate)]]
                    for legacy in LEGACY_VOTING_HEADERS
                ):
                    continue
                if normalized_type == VOTING_SECTION_END_MARKER:
                    continue

                poll_id = self._normalize_cell_text(poll_id_cell)
                if not poll_id:
                    continue

                entry = voting_entries.setdefault(
                    poll_id,
                    {
                        "poll_id": poll_id,
                        "topic_template": "",
                        "options_raw": [],
                        "weekdays": set(),
                        "metadata": {},
                        "comments": [],
                        "topic_id_value": "",
                    },
                )

                topic_value = topic_cell
                option_text = option_cell
                weekday_value = weekday_cell
                comment_value = comment_cell
                anon_value = self._parse_bool_value(anon_cell)
                multiple_value = self._parse_bool_value(multiple_cell)
                open_period_value = self._try_parse_int(open_period_cell)
                close_date_value = self._normalize_cell_text(close_date_cell)
                topic_id_value = topic_id_cell

                if topic_value:
                    entry["topic_template"] = topic_value

                if option_text:
                    entry["options_raw"].append(
                        {
                            "text": option_text,
                            "sequence": len(entry["options_raw"]),
                            "comment": comment_value,
                        }
                    )

                if weekday_value:
                    for part in re.split(r"[,\n;/]+", str(weekday_value)):
                        weekday = self._parse_weekday_value(part)
                        if weekday is not None:
                            entry["weekdays"].add(weekday)

                if comment_value:
                    entry["comments"].append(comment_value)
                if anon_value is not None:
                    entry["metadata"]["is_anonymous"] = anon_value
                if multiple_value is not None:
                    entry["metadata"]["allows_multiple_answers"] = multiple_value
                if open_period_value is not None:
                    entry["metadata"]["open_period_minutes"] = open_period_value
                if close_date_value:
                    entry["metadata"]["close_date"] = close_date_value
                if topic_id_value:
                    entry["topic_id_value"] = topic_id_value

            for team in teams.values():
                if isinstance(team.get("comp_ids"), set):
                    team["comp_ids"] = sorted(team["comp_ids"])
                if not team.get("metadata"):
                    team.pop("metadata", None)
                if not team.get("alt_name"):
                    team.pop("alt_name", None)

            voting_polls: List[Dict[str, Any]] = []
            for poll_id, data in voting_entries.items():
                options_raw = data.pop("options_raw", [])
                if options_raw:
                    options_sorted = sorted(options_raw, key=lambda item: item["sequence"])
                    data["options"] = [
                        {
                            "text": option["text"],
                            "comment": option["comment"],
                        }
                        for option in options_sorted
                    ]
                else:
                    data["options"] = []
                weekdays = data.get("weekdays", set())
                data["weekdays"] = sorted(weekdays) if isinstance(weekdays, set) else weekdays
                topic_id_value = data.pop("topic_id_value", "")
                if topic_id_value:
                    topic_id_parsed = self._try_parse_int(topic_id_value)
                    if topic_id_parsed is not None:
                        data["topic_id"] = topic_id_parsed
                    else:
                        data["topic_raw"] = topic_id_value
                if not data.get("comments"):
                    data.pop("comments", None)
                voting_polls.append(data)

            automation_header_index: Optional[int] = None
            for idx, row in enumerate(all_data):
                candidate = [cell.strip() for cell in row[:len(AUTOMATION_SECTION_HEADER)]]
                if candidate == AUTOMATION_SECTION_HEADER:
                    automation_header_index = idx
                    break
                for legacy in LEGACY_AUTOMATION_HEADERS:
                    if candidate[:len(legacy)] == [cell.strip() for cell in legacy]:
                        automation_header_index = idx
                        break
                if automation_header_index is not None:
                    break
            if automation_header_index is not None:
                for row in all_data[automation_header_index + 1:]:
                    if not row or len(row) == 0:
                        continue
                    raw_label = self._normalize_cell_text(row[0])
                    if not raw_label:
                        continue
                    if raw_label.upper() == AUTOMATION_SECTION_END_MARKER:
                        break
                    topic_raw = self._normalize_cell_text(row[1]) if len(row) > 1 else ""
                    anon_raw = row[2] if len(row) > 2 else ""
                    multiple_raw = row[3] if len(row) > 3 else ""
                    comment_raw = self._normalize_cell_text(row[4]) if len(row) > 4 else ""
                    mapped_key = AUTOMATION_NAME_TO_KEY.get(raw_label.lower())
                    key_upper = mapped_key.upper() if mapped_key else raw_label.upper()
                    entry: Dict[str, Any] = {}
                    display_name = AUTOMATION_KEY_TO_NAME.get(key_upper, raw_label)
                    if display_name:
                        entry["name"] = display_name
                    topic_id_value = self._try_parse_int(topic_raw)
                    if topic_id_value is not None:
                        entry["topic_id"] = topic_id_value
                    elif topic_raw:
                        entry["topic_raw"] = topic_raw
                    anon_value = self._parse_bool_value(anon_raw)
                    if anon_value is not None:
                        entry["is_anonymous"] = anon_value
                    multiple_value = self._parse_bool_value(multiple_raw)
                    if multiple_value is not None:
                        entry["allows_multiple_answers"] = multiple_value
                    if comment_raw:
                        entry["comment"] = comment_raw
                    automation_topics[key_upper] = entry

            has_data = bool(
                comp_ids_set
                or team_ids_set
                or teams
                or training_polls
                or fallback_sources
                or voting_polls
                or automation_topics
            )
            payload.update({
                'comp_ids': sorted(comp_ids_set),
                'team_ids': sorted(team_ids_set),
                'teams': teams,
                'training_polls': training_polls,
                'fallback_sources': fallback_sources,
                'voting_polls': sorted(voting_polls, key=lambda item: item.get("poll_id") or ""),
                'automation_topics': automation_topics,
            })
            return {'has_data': has_data, 'payload': payload}
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ –ª–∏—Å—Ç–∞ '{CONFIG_WORKSHEET_NAME}': {e}")
            return {'has_data': False, 'payload': payload}

    def _read_config_from_service_sheet(self) -> Dict[str, Any]:
        worksheet = self._get_service_worksheet()
        if not worksheet:
            return {
                'comp_ids': set(),
                'team_ids': set(),
                'teams': {},
                'training_polls': [],
                'fallback_sources': [],
                'voting_polls': []
            }

        try:
            all_data = worksheet.get_all_values()
            if not all_data:
                return {
                    'comp_ids': set(),
                    'team_ids': set(),
                    'teams': {},
                    'training_polls': [],
                    'fallback_sources': [],
                    'voting_polls': []
                }

            comp_ids_set: Set[int] = set()
            team_ids_set: Set[int] = set()
            teams: Dict[int, Dict[str, Any]] = {}
            training_polls: List[Dict[str, Any]] = []
            fallback_sources: List[Dict[str, Any]] = []

            for row in all_data[1:]:
                if len(row) <= TYPE_COL:
                    continue

                row_type = (row[TYPE_COL] or "").strip().upper()
                if not row_type:
                    continue

                row_comp_ids = self._parse_ids(row[COMP_ID_COL]) if len(row) > COMP_ID_COL else []
                row_team_ids = self._parse_ids(row[TEAM_ID_COL]) if len(row) > TEAM_ID_COL else []
                alt_name = (row[ALT_NAME_COL] or "").strip() if len(row) > ALT_NAME_COL else ""
                config_payload = self._parse_json_config(row[CONFIG_COL] if len(row) > CONFIG_COL else "")

                if row_type in {"CONFIG", "CONFIG_IDS", "CONFIG_ROW", "CONFIG_COMP", "COMP_CONFIG"}:
                    comp_ids_set.update(row_comp_ids)

                if row_type in {"CONFIG", "CONFIG_IDS", "CONFIG_ROW", "CONFIG_TEAM", "TEAM_CONFIG"}:
                    comp_ids_set.update(row_comp_ids)
                    for team_id in row_team_ids:
                        team_ids_set.add(team_id)
                        team_entry = teams.setdefault(team_id, {"alt_name": None, "comp_ids": set(), "metadata": {}})
                        if alt_name:
                            team_entry["alt_name"] = alt_name
                        if row_comp_ids:
                            team_entry["comp_ids"].update(row_comp_ids)
                        if config_payload:
                            team_entry["metadata"].update(config_payload)

                elif row_type in {"TRAINING_POLL", "TRAINING_CONFIG"}:
                    training_entry = {
                        "title": config_payload.get("title") or (row[ADDITIONAL_DATA_COL] if len(row) > ADDITIONAL_DATA_COL else ""),
                        "weekday": config_payload.get("weekday"),
                        "time": config_payload.get("time") or (row[STATUS_COL] if len(row) > STATUS_COL else ""),
                        "location": config_payload.get("location") or (row[LINK_COL] if len(row) > LINK_COL else ""),
                        "topic_id": config_payload.get("topic_id"),
                        "metadata": config_payload
                    }
                    training_polls.append(training_entry)

                elif row_type in {"FALLBACK", "FALLBACK_SOURCE", "FALLBACK_CONFIG"}:
                    fallback_entry = {
                        "name": config_payload.get("name") or alt_name or (row[ADDITIONAL_DATA_COL] if len(row) > ADDITIONAL_DATA_COL else ""),
                        "url": config_payload.get("url") or (row[LINK_COL] if len(row) > LINK_COL else ""),
                        "metadata": config_payload
                    }
                    fallback_sources.append(fallback_entry)

                else:
                    if row_comp_ids:
                        comp_ids_set.update(row_comp_ids)
                    if row_team_ids:
                        for team_id in row_team_ids:
                            team_ids_set.add(team_id)
                            team_entry = teams.setdefault(team_id, {"alt_name": None, "comp_ids": set(), "metadata": {}})
                            if alt_name:
                                team_entry["alt_name"] = alt_name
                            if config_payload:
                                team_entry["metadata"].update(config_payload)

            for team in teams.values():
                if isinstance(team.get("comp_ids"), set):
                    team["comp_ids"] = sorted(team["comp_ids"])
                if not team.get("metadata"):
                    team.pop("metadata", None)
                if not team.get("alt_name"):
                    team.pop("alt_name", None)

            return {
                'comp_ids': comp_ids_set,
                'team_ids': team_ids_set,
                'teams': teams,
                'training_polls': training_polls,
                'fallback_sources': fallback_sources,
                'voting_polls': [],
                'automation_topics': {}
            }
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –ª–∏—Å—Ç–∞: {e}")
            return {
                'comp_ids': set(),
                'team_ids': set(),
                'teams': {},
                'training_polls': [],
                'fallback_sources': [],
                'voting_polls': [],
                'automation_topics': {}
            }

    def get_config_ids(self) -> Dict[str, Any]:
        """–°–æ–≤–º–µ—Å—Ç–∏–º–∞—è –æ–±—ë—Ä—Ç–∫–∞ –≤–æ–∫—Ä—É–≥ –ø–æ–ª–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        full_config = self.get_full_config()
        return {
            'comp_ids': sorted(full_config.get('comp_ids', set())),
            'team_ids': sorted(full_config.get('team_ids', set())),
            'teams': full_config.get('teams', {}),
            'training_polls': full_config.get('training_polls', []),
            'fallback_sources': full_config.get('fallback_sources', []),
            'voting_polls': full_config.get('voting_polls', []),
            'automation_topics': full_config.get('automation_topics', {}),
        }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö –º–æ–¥—É–ª—è—Ö
duplicate_protection = EnhancedDuplicateProtection()

def test_duplicate_protection():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º—É –∑–∞—â–∏—Ç—ã –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –£–°–ò–õ–ï–ù–ù–û–ô –°–ò–°–¢–ï–ú–´ –ó–ê–©–ò–¢–´ –û–¢ –î–£–ë–õ–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 70)
    
    if not duplicate_protection.gc:
        print("‚ùå Google Sheets –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω")
        return False
    
    if not duplicate_protection.service_worksheet:
        print("‚ùå –õ–∏—Å—Ç '–°–µ—Ä–≤–∏—Å–Ω—ã–π' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    
    print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é")
    
    # –¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–∞
    print(f"\nüß™ –¢–ï–°–¢ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–∞")
    duplicate_check = duplicate_protection.check_duplicate("–û–ü–†–û–°_–¢–†–ï–ù–ò–†–û–í–ö–ê", "5312150808802889330")
    print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {duplicate_check}")
    
    # –¢–µ—Å—Ç 2: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏
    print(f"\nüß™ –¢–ï–°–¢ 2: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏")
    new_record = duplicate_protection.add_record(
        "–¢–ï–°–¢_–ó–ê–ü–ò–°–¨", 
        "test_001", 
        "–ê–ö–¢–ò–í–ï–ù", 
        "–¢–µ—Å—Ç–æ–≤–∞—è –∑–∞–ø–∏—Å—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏"
    )
    print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {new_record}")
    
    # –¢–µ—Å—Ç 3: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print(f"\nüß™ –¢–ï–°–¢ 3: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
    stats = duplicate_protection.get_statistics()
    print(f"   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}")
    
    # –¢–µ—Å—Ç 4: –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –ø–æ —Ç–∏–ø—É
    print(f"\nüß™ –¢–ï–°–¢ 4: –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –ø–æ —Ç–∏–ø—É")
    training_records = duplicate_protection.get_records_by_type("–û–ü–†–û–°_–¢–†–ï–ù–ò–†–û–í–ö–ê")
    print(f"   –ó–∞–ø–∏—Å–∏ –æ–ø—Ä–æ—Å–æ–≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫: {len(training_records)}")
    
    print(f"\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    return True

if __name__ == "__main__":
    test_duplicate_protection()
